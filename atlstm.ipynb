{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from torch.functional import F\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_gened.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    print(f\"DataFrame占用大小 {start_mem:.2f} MB\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"DataFrame优化后占用大小: {end_mem:.2f} MB\")\n",
    "    decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(f\"优化了 {decrease:.2f}%\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据载入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cols = [c for c in df.columns if c not in ['row_id', 'time_id', 'date_id', 'target']]\n",
    "y_cols = [\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_features(x, means, stds):\n",
    "    return (x - means) / (stds + 1e-8)\n",
    "\n",
    "def get_xy(df, x_cols, y_cols, means, stds):\n",
    "    x = df[x_cols]\n",
    "    x = normalize_features(x, means, stds)\n",
    "    y = df[y_cols]\n",
    "    return x.values, y.values\n",
    "\n",
    "def get_dataloaders(df, x_cols, y_cols, batch_size=512):\n",
    "    # 划分训练集和测试集\n",
    "    train_size = int(len(df) * 0.8)\n",
    "    valid_size = len(df) - train_size\n",
    "    train_df, valid_df = random_split(df, [train_size, valid_size])\n",
    "\n",
    "    # 计算训练集的均值和标准差用于标准化\n",
    "    means = train_df.dataset.loc[train_df.indices][x_cols].mean()\n",
    "    stds = train_df.dataset.loc[train_df.indices][x_cols].std()\n",
    "\n",
    "    # 获取标准化后的训练集和测试集\n",
    "    x_train, y_train = get_xy(train_df.dataset.loc[train_df.indices], x_cols, y_cols, means, stds)\n",
    "    x_valid, y_valid = get_xy(valid_df.dataset.loc[valid_df.indices], x_cols, y_cols, means, stds)\n",
    "\n",
    "    # 转换为 PyTorch 张量\n",
    "    train_dataset = TensorDataset(torch.Tensor(x_train).to(device), torch.Tensor(y_train).to(device))\n",
    "    test_dataset = TensorDataset(torch.Tensor(x_valid).to(device), torch.Tensor(y_valid).to(device))\n",
    "\n",
    "    # 创建 DataLoader\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=min(batch_size * 4, len(test_dataset)), drop_last=True)\n",
    "\n",
    "    return train_dataloader, test_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader, test_dataloader = get_dataloaders(df, x_cols, y_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 81]) torch.Size([512, 1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer, shortcut=0):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    num_batches = len(dataloader)\n",
    "\n",
    "    train_loss = 0\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        pred = model(X)\n",
    "        \n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if pred.std() < 0.000001:\n",
    "            print(\"WARNING: std() is zero, stopping\")\n",
    "            break\n",
    "        \n",
    "        if shortcut > 0 and batch == shortcut:\n",
    "            return train_loss.detach().cpu().numpy() / shortcut\n",
    "    return train_loss.detach().cpu().numpy() / num_batches\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "      \n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).detach().cpu().numpy()\n",
    "    \n",
    "        scheduler.step(test_loss)\n",
    "    return test_loss / num_batches\n",
    "        \n",
    "def predict(X, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model(X)\n",
    "    return pred.detach().cpu().numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopper:\n",
    "    def __init__(self, patience=10, min_delta=0.00001):\n",
    "        self.best_model = None\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "        \n",
    "    def get_best_model(self):\n",
    "        return self.best_model\n",
    "\n",
    "    def early_stop(self, validation_loss, model):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            print(f\"New best loss: {validation_loss:>4f}\")\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "            self.best_model = model\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_rnn(rnn, init_type='xavier'):\n",
    "    for name, param in rnn.named_parameters():\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)\n",
    "        elif 'weight' in name:\n",
    "            if init_type == 'xavier':\n",
    "                nn.init.xavier_normal_(param)\n",
    "            else:\n",
    "                nn.init.normal_(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size=81, hidden_layer_size=50, output_size=1, num_layers=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = 1   \n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=20, kernel_size=2)\n",
    "        self.lstm = nn.LSTM(20, hidden_layer_size, num_layers, dropout=0.2)\n",
    "\n",
    "        self.linear_adjust = nn.Linear(hidden_layer_size, hidden_layer_size) \n",
    "        self.fc1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        self.risidual = nn.Linear(hidden_layer_size, 1)\n",
    "\n",
    "        init_rnn(self.lstm, 'xavier')\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        input_seq = input_seq.unsqueeze(0).permute(0, 2, 1)\n",
    "        input_seq = self.conv1d(input_seq)\n",
    "        input_seq = input_seq.permute(0, 2, 1)\n",
    "        lstm_out, (hidden, _) = self.lstm(input_seq.reshape(len(input_seq[0]), 1, 20))\n",
    "        \n",
    "        adjusted_lstm_out = self.linear_adjust(lstm_out[-1])\n",
    "\n",
    "        out = self.fc1(adjusted_lstm_out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        out = torch.tanh(out)\n",
    "\n",
    "        return out[-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原始AT-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMwithAttention_1(nn.Module):\n",
    "    def __init__(self, input_size=81, hidden_layer_size=50, output_size=1, num_layers=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = 1   \n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=35, kernel_size=2)\n",
    "        self.lstm = nn.LSTM(20, hidden_layer_size, num_layers, dropout=0.2)\n",
    "\n",
    "        # 使用ReLU激活函数\n",
    "        self.fc1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.attn_weights = None\n",
    "\n",
    "        # 初始化LSTM层的权重\n",
    "        init_rnn(self.lstm, type='xavier')\n",
    "\n",
    "\n",
    "\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        lstm_output = lstm_output.permute(1, 0, 2)\n",
    "        hidden = final_state.view(-1, self.hidden_layer_size, self.num_layers)\n",
    "        self.attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)\n",
    "\n",
    "        soft_attn_weights = F.tanh(self.attn_weights)\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights).squeeze(2)\n",
    "        return context \n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        input_seq = input_seq.unsqueeze(0).permute(0, 2, 1)\n",
    "        input_seq = self.conv1d(input_seq)\n",
    "        input_seq = input_seq.permute(0, 2, 1)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.reshape(len(input_seq[0]), 1, 20))\n",
    "\n",
    "        attn_output = self.attention_net(lstm_out, self.hidden_cell[0])\n",
    "        \n",
    "        out = self.fc1(attn_output.view(-1, self.hidden_layer_size))\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        \n",
    "        return out[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM与输出残差连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMwithAttention_2(nn.Module):\n",
    "    def __init__(self, input_size=81, hidden_layer_size=50, output_size=1, num_layers=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = 1   \n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=20, kernel_size=2)\n",
    "        self.lstm = nn.LSTM(20, hidden_layer_size, num_layers, dropout=0.2)\n",
    "\n",
    "        self.linear_adjust = nn.Linear(hidden_layer_size, hidden_layer_size) # 调整维度的线性层\n",
    "\n",
    "        self.fc1 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_layer_size, hidden_layer_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.attn_weights = None\n",
    "        self.risidual = nn.Linear(hidden_layer_size, 1)\n",
    "\n",
    "        init_rnn(self.lstm, 'xavier')\n",
    "\n",
    "\n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        lstm_output = lstm_output.permute(1, 0, 2)\n",
    "        hidden = final_state.view(-1, self.hidden_layer_size, self.num_layers)\n",
    "        self.attn_weights = torch.bmm(lstm_output, hidden).squeeze(2)\n",
    "\n",
    "        soft_attn_weights = torch.tanh(self.attn_weights)\n",
    "        context = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights).squeeze(2)\n",
    "        return context \n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        input_seq = input_seq.unsqueeze(0).permute(0, 2, 1)\n",
    "        input_seq = self.conv1d(input_seq)\n",
    "        input_seq = input_seq.permute(0, 2, 1)\n",
    "        lstm_out, self.hidden_cell = self.lstm(input_seq.reshape(len(input_seq[0]), 1, 20))\n",
    "\n",
    "        # 调整LSTM输出的维度\n",
    "        adjusted_lstm_out = self.linear_adjust(lstm_out[-1])\n",
    "        # print(f'adjusted_lstm_out.shape: {adjusted_lstm_out.shape}')\n",
    "\n",
    "        attn_output = self.attention_net(lstm_out, self.hidden_cell[0])\n",
    "        # print(f'attn_output.shape: {attn_output.shape}')\n",
    "        \n",
    "        # 线性层处理\n",
    "        out = self.fc1(attn_output.view(-1, self.hidden_layer_size))\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "\n",
    "        \n",
    "        # 添加残差连接\n",
    "        out = self.risidual(adjusted_lstm_out) + out\n",
    "        # print(f'2out.shape: {out.shape}')\n",
    "        out = torch.tanh(out)\n",
    "\n",
    "        return out[-1]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用加性注意力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMwithAttention_3(nn.Module):\n",
    "    def __init__(self, input_size=81, hidden_layer_size=50, output_size=1, num_layers=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.num_layers = num_layers\n",
    "        self.batch_size = 1   \n",
    "\n",
    "        self.conv1d = nn.Conv1d(in_channels=input_size, out_channels=20, kernel_size=2)\n",
    "        self.lstm = nn.LSTM(20, hidden_layer_size, num_layers, dropout=0.2)\n",
    "\n",
    "        self.linear_adjust = nn.Linear(hidden_layer_size, hidden_layer_size) \n",
    "        self.fc1 = nn.Linear(hidden_layer_size, 206)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(206, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "        # 注意力机制的组件\n",
    "        self.attention_linear = nn.Linear(2 * hidden_layer_size, hidden_layer_size)\n",
    "        self.attention_vector = nn.Parameter(torch.randn(hidden_layer_size))\n",
    "\n",
    "        self.risidual = nn.Linear(hidden_layer_size, 1)\n",
    "\n",
    "        init_rnn(self.lstm, 'xavier')\n",
    "        \n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        hidden = final_state.repeat(lstm_output.size(0), 1, 1).transpose(0, 1)\n",
    "        lstm_output = lstm_output.transpose(0, 1)\n",
    "        attn_input = torch.cat((lstm_output, hidden), 2)\n",
    "        energy = torch.tanh(self.attention_linear(attn_input))\n",
    "        attention = torch.matmul(energy, self.attention_vector)\n",
    "        attention_weights = F.softmax(attention, dim=1)\n",
    "\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), attention_weights.unsqueeze(2)).squeeze(2)\n",
    "        return new_hidden_state\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        input_seq = input_seq.unsqueeze(0).permute(0, 2, 1)\n",
    "        # print(f'input_seq.shape: {input_seq.shape}')\n",
    "        input_seq = self.conv1d(input_seq)\n",
    "        # print(f'after conv1d, input_seq.shape: {input_seq.shape}')\n",
    "        input_seq = input_seq.permute(0, 2, 1)\n",
    "        # print(f'after permute, input_seq.shape: {input_seq.shape}')\n",
    "        lstm_out, (hidden, _) = self.lstm(input_seq.reshape(len(input_seq[0]), 1, 20))\n",
    "        # print(f'lstm_out.shape: {lstm_out.shape}')\n",
    "        adjusted_lstm_out = self.linear_adjust(lstm_out[-1])\n",
    "        \n",
    "        attn_output = self.attention_net(lstm_out, hidden[-1])\n",
    "        # print(f'attn_out.shape: {attn_output.shape}')\n",
    "\n",
    "        out = self.fc1(attn_output.view(-1, self.hidden_layer_size))\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.fc3(out)\n",
    "        # print(f'out.shape: {out.shape}')\n",
    "        out = self.risidual(adjusted_lstm_out) + out\n",
    "        # print(f'2out.shape: {out.shape}')\n",
    "        out = torch.tanh(out).transpose(0, 1)\n",
    "        # print(f'3out.shape: {out.shape}')\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMwithAttention_3().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0008, weight_decay=0.00001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=8, factor=0.5, verbose=True)\n",
    "early_stopper = EarlyStopper(patience=15, min_delta=0.0001)\n",
    "\n",
    "loss_fn = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   1 Train: 6.409966 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhiwei\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning: Using a target size (torch.Size([2048, 1])) that is different to the input size (torch.Size([512, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.l1_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (512) must match the size of tensor b (2048) at non-singleton dimension 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\project\\kaggle\\closing_auction_premodel\\atlstm.ipynb 单元格 24\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m train_loss \u001b[39m=\u001b[39m train_loop(train_dataloader, model, loss_fn, optimizer, shortcut\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTrain: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m>5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m test_loss \u001b[39m=\u001b[39m test_loop(test_dataloader, model, loss_fn)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m| Test: \u001b[39m\u001b[39m{\u001b[39;00mtest_loss\u001b[39m:\u001b[39;00m\u001b[39m>5f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mif\u001b[39;00m early_stopper\u001b[39m.\u001b[39mearly_stop(test_loss, model) \u001b[39mor\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m t1 \u001b[39m>\u001b[39m \u001b[39m60\u001b[39m\u001b[39m*\u001b[39m\u001b[39m60\u001b[39m\u001b[39m*\u001b[39m\u001b[39m8\u001b[39m:  \n",
      "\u001b[1;32md:\\project\\kaggle\\closing_auction_premodel\\atlstm.ipynb 单元格 24\u001b[0m line \u001b[0;36m4\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     \u001b[39mfor\u001b[39;00m X, y \u001b[39min\u001b[39;00m dataloader:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m         pred \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m         test_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_fn(pred, y)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m     scheduler\u001b[39m.\u001b[39mstep(test_loss)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/project/kaggle/closing_auction_premodel/atlstm.ipynb#X30sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m \u001b[39mreturn\u001b[39;00m test_loss \u001b[39m/\u001b[39m num_batches\n",
      "File \u001b[1;32mc:\\Users\\zhiwei\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\zhiwei\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\zhiwei\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101\u001b[0m, in \u001b[0;36mL1Loss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor, target: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49ml1_loss(\u001b[39minput\u001b[39;49m, target, reduction\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreduction)\n",
      "File \u001b[1;32mc:\\Users\\zhiwei\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\functional.py:3297\u001b[0m, in \u001b[0;36ml1_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3294\u001b[0m \u001b[39mif\u001b[39;00m size_average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3295\u001b[0m     reduction \u001b[39m=\u001b[39m _Reduction\u001b[39m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3297\u001b[0m expanded_input, expanded_target \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbroadcast_tensors(\u001b[39minput\u001b[39;49m, target)\n\u001b[0;32m   3298\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_nn\u001b[39m.\u001b[39ml1_loss(expanded_input, expanded_target, _Reduction\u001b[39m.\u001b[39mget_enum(reduction))\n",
      "File \u001b[1;32mc:\\Users\\zhiwei\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\functional.py:73\u001b[0m, in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function(tensors):\n\u001b[0;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(broadcast_tensors, tensors, \u001b[39m*\u001b[39mtensors)\n\u001b[1;32m---> 73\u001b[0m \u001b[39mreturn\u001b[39;00m _VF\u001b[39m.\u001b[39;49mbroadcast_tensors(tensors)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (2048) at non-singleton dimension 0"
     ]
    }
   ],
   "source": [
    "history = pd.DataFrame([], columns=[\"epoch\",\"train_loss\",\"test_loss\",\"lr\"])\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "for epoch in range(20):\n",
    "    \n",
    "    print(f\"Epoch {epoch+1:>3d}\",end=\" \")\n",
    "    train_loss = train_loop(train_dataloader, model, loss_fn, optimizer, shortcut=0)\n",
    "    print(f\"Train: {train_loss:>5f}\", end=\" \")\n",
    "    test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    print(f\"| Test: {test_loss:>5f}\")\n",
    "\n",
    "    if early_stopper.early_stop(test_loss, model) or time.time() - t1 > 60*60*8:  \n",
    "        model = early_stopper.get_best_model()\n",
    "        break\n",
    "\n",
    "    history.loc[len(history),:] = [epoch+1, train_loss, test_loss, optimizer.param_groups[0]['lr']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6.409797</td>\n",
       "      <td>6.398921</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>6.409755</td>\n",
       "      <td>6.398902</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>6.40979</td>\n",
       "      <td>6.398913</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6.409748</td>\n",
       "      <td>6.398913</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6.409716</td>\n",
       "      <td>6.398977</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>6.409779</td>\n",
       "      <td>6.3989</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>6.409784</td>\n",
       "      <td>6.398911</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6.409763</td>\n",
       "      <td>6.3989</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>6.409755</td>\n",
       "      <td>6.398926</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  epoch train_loss test_loss      lr\n",
       "0     1   6.409797  6.398921  0.0008\n",
       "1     2   6.409755  6.398902  0.0008\n",
       "2     3    6.40979  6.398913  0.0008\n",
       "3     4   6.409748  6.398913  0.0008\n",
       "4     5   6.409716  6.398977  0.0008\n",
       "5     6   6.409779    6.3989  0.0008\n",
       "6     7   6.409784  6.398911  0.0008\n",
       "7     8   6.409763    6.3989  0.0008\n",
       "8     9   6.409755  6.398926  0.0008"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history['train_loss'], label='train_loss',color='red')\n",
    "plt.plot(history['test_loss'], label='test_loss',color='blue')\n",
    "\n",
    "plt.ylim(6.395, 6.419)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.to_csv(\"history_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zhiwei\\anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\loss.py:101: UserWarning:\n",
      "\n",
      "Using a target size (torch.Size([2048, 1])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "mae = test_loop(test_dataloader, model, loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.416089995733213"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2797.34 MB\n",
      "Memory usage after optimization is: 914.13 MB\n",
      "Decreased by 67.32%\n"
     ]
    }
   ],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "\n",
    "    print(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "    decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "    print(f\"Decreased by {decrease:.2f}%\")\n",
    "\n",
    "    return df\n",
    "\n",
    "df = reduce_mem_usage(df, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
